{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
       "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
       "        1, 7, 6, 9])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "example_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(example_data[i][0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully connected neural network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.2313\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3441\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2916\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1619\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1330\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1528\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1371\n",
      "Epoch [2/2], Step [200/600], Loss: 0.2011\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1142\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0845\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1061\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1481\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model<br>\n",
    "In test phase, we don't need to compute gradients (for memory efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.66 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with torch.inference_mode():\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_sample = [0 for i in range(10)]\n",
    "    for img,labels in test_loader:\n",
    "        img = img.reshape(-1,28*28)\n",
    "        output_logit = model(img)\n",
    "        predicted = torch.argmax(output_logit,dim=1)\n",
    "        correct = (labels==predicted).sum().item()\n",
    "        acc = correct/len(test_loader) * 100\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label==pred):\n",
    "                n_class_correct[label] += 1\n",
    "                n_class_sample[label] += 1\n",
    "        print(n_class_correct,)\n",
    "            \n",
    "#         print(f\"accuracy: {acc}\")\n",
    "#     for i in range(10):\n",
    "#         acc = 100*n_class_correct[i]/n_class_sample[i]\n",
    "#         print(f\"acc of  {classes[i]}:{acc}%\")\n",
    "            \n",
    "# print(labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\pouya\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\pouya\\appdata\\roaming\\python\\python39\\site-packages (2.0.1)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp39-cp39-win_amd64.whl (2619.2 MB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\pouya\\appdata\\roaming\\python\\python39\\site-packages (0.15.2)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp39-cp39-win_amd64.whl (4.9 MB)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\pouya\\appdata\\roaming\\python\\python39\\site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.15.2\n",
      "    Uninstalling torchvision-0.15.2:\n",
      "      Successfully uninstalled torchvision-0.15.2\n",
      "Successfully installed torch-2.0.1+cu118 torchvision-0.15.2+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
