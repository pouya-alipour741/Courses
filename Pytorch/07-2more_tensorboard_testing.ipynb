{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d501ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b32c6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eac528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b89ee39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,in_channels = 3,hidden_unit=8, num_classes = 10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,hidden_unit,kernel_size=3, stride=1, padding=1) \n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(hidden_unit,out_channels=16,kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)   ###or use nn.Flatten() in __init__ method\n",
    "        x = self.fc1(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba60ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "learning_rate = 0.001\n",
    "in_channel = 1\n",
    "hidden_unit = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1d05d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(in_channel,hidden_unit,num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58a2d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "# summary(model,\n",
    "#         input_size=(32,3,224,244),\n",
    "#        col_names=[\"input_size\",\"output_size\"],\n",
    "#        row_setting=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fbd1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7774dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\"data/\",train=True,transform=simple_transform\n",
    "                            ,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01275f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bd6b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f308141",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.001]\n",
    "batch_sizes = [256]\n",
    "classes = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4d34e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "# next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d7caab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647857fd30794fd7a9031637cfb4c9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "len label: 96,len dataloader:235,image.shape[0]: 96,batch:234, batch size: 256\n",
      "total train time took 34.60019860000011 for batch size: 256 and learning rate: 0.001 with 1 epochs\n",
      "operation finished\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "step = 0\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "            train_dataloader = DataLoader(train_data, batch_size, shuffle=True)\n",
    "            writer = SummaryWriter(f\"runs\\MiniBatchSize {batch_size} lr {learning_rate}\")\n",
    "            model.train()\n",
    "#         for epochs in num_epochs:\n",
    "            train_start_time = perf_counter()\n",
    "            \n",
    "            for epoch in tqdm(range(epochs)):\n",
    "                losses = []\n",
    "                accuracies = []\n",
    "#                 results = defaultdict(list)\n",
    "\n",
    "                for batch, (image, label) in enumerate(train_dataloader):\n",
    "                                     \n",
    "                    image, label = image.to(device), label.to(device)\n",
    "                    \n",
    "                    logits = model(image)\n",
    "                    pred_prob = torch.softmax(logits,dim=1)\n",
    "                    pred_label = torch.argmax(pred_prob, dim=1)\n",
    "                    \n",
    "                    loss = loss_fn(logits,label)\n",
    "                    losses.append(loss.item())\n",
    "                    \n",
    "                    acc = torch.eq(label,pred_label).sum()/len(label)\n",
    "                    accuracies.append(acc)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    features = image.reshape(image.shape[0],-1)\n",
    "                    class_labels = [classes[target] for target in label]\n",
    "                    img_grid = torchvision.utils.make_grid(image)\n",
    "                    writer.add_image(\"mnist_images\",img_grid)\n",
    "                    writer.add_histogram(\"fc1\",model.fc1.weight)\n",
    "                    \n",
    "                    writer.add_scalar(\"train_loss\",loss,global_step=step)\n",
    "                    writer.add_scalar(\"train_acc\",acc,global_step=step)\n",
    "                    \n",
    "                    if batch == 230:   ### 60000 samples / 256 batch size\n",
    "                        writer.add_embedding(features, metadata= class_labels,\n",
    "                                            label_img=image,global_step=batch)\n",
    "                    \n",
    "                    step+=1\n",
    "                    \n",
    "                    if batch ==len(train_dataloader)-1:\n",
    "                        print(f\"len label: {len(label)},len dataloader:{len(train_dataloader)},image.shape[0]: {image.shape[0]},batch:{batch}, batch size: {batch_size}\")\n",
    "            writer.add_hparams({\"lr\":learning_rate, \"bsize\":batch_size },\n",
    "                              {\"accuracy\":sum(accuracies)/len(accuracies),\n",
    "                              \"loss\":sum(losses)/len(losses)})\n",
    "                                                                          \n",
    "                \n",
    "            train_end_time = perf_counter()\n",
    "            print(f\"total train time took {train_end_time-train_start_time} for batch size: {batch_size} and learning rate: {learning_rate} with {epochs} epochs\")\n",
    "print(\"operation finished\")            \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed358d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.375"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a824fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee1a6801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19884), started 0:00:19 ago. (Use '!kill 19884' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-750721689373db70\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-750721689373db70\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
