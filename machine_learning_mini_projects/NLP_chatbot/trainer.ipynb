{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6f138104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile Modules/train.py\n",
    "import json\n",
    "from Modules.nltk_utils import tokenize, stem, bag_of_words\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from Modules.model import NeuralNet\n",
    "from torchinfo import summary\n",
    "\n",
    "with open(\"intents.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ab638e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "\n",
    "for intent in data[\"intents\"]:\n",
    "    tag = intent[\"tag\"]\n",
    "    tags.append(tag)\n",
    "    \n",
    "    for pattern in intent[\"patterns\"]:\n",
    "        w = tokenize(pattern)\n",
    "#         print(w)\n",
    "        all_words.extend(w)\n",
    "        xy.append((w, tag))\n",
    "\n",
    "ignore_words = [\"?\", \"!\", \".\", \",\"]   \n",
    "\n",
    "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))\n",
    "# print(all_words)\n",
    " \n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for (pattern_sentence, tag) in xy:\n",
    "    bag = bag_of_words(pattern_sentence, all_words)\n",
    "    x_train.append(bag)\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "y_train = torch.tensor(y_train)\n",
    "x_train = torch.tensor(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5e84e136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 58])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ChatDataSet(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(x_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_train[idx], self.y_train[idx]\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 8\n",
    "input_size = len(x_train[0])  #len(x_train[0]) same as len(all_words) same as len(bag)\n",
    "hidden_size = 8\n",
    "num_classes = len(tags)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "\n",
    "dataset = ChatDataSet(x_train, y_train)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ed749aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "428f456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "611e9ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "788cd908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape      Param #           Trainable         Mult-Adds\n",
       "============================================================================================================\n",
       "NeuralNet                                [8, 7]            --                True              --\n",
       "├─Linear: 1-1                            [8, 8]            472               True              3,776\n",
       "├─ReLU: 1-2                              [8, 8]            --                --                --\n",
       "├─Linear: 1-3                            [8, 8]            72                True              576\n",
       "├─ReLU: 1-4                              [8, 8]            --                --                --\n",
       "├─Linear: 1-5                            [8, 7]            63                True              504\n",
       "============================================================================================================\n",
       "Total params: 607\n",
       "Trainable params: 607\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "============================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "============================================================================================================"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model,\n",
    "        input_size=(batch_size, len(bag)),\n",
    "        col_names=[\"output_size\", \"num_params\", \"trainable\", \"mult_adds\"],\n",
    "        col_width=17,\n",
    "#         row_settings=[\"var_names\"]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "251db2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0e3a0542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "233ca740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde75258c2e84dbea8e5cd3b2477d4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20/1000 |train loss: 1.903\n",
      "epoch:110/1000 |train loss: 0.730\n",
      "epoch:200/1000 |train loss: 0.069\n",
      "epoch:290/1000 |train loss: 0.020\n",
      "epoch:380/1000 |train loss: 0.009\n",
      "epoch:470/1000 |train loss: 0.005\n",
      "epoch:560/1000 |train loss: 0.003\n",
      "epoch:650/1000 |train loss: 0.002\n",
      "epoch:740/1000 |train loss: 0.001\n",
      "epoch:830/1000 |train loss: 0.001\n",
      "epoch:920/1000 |train loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = 0\n",
    "    for (words, labels) in train_loader:\n",
    "        words = words.to(device)\n",
    "        labels = labels.to(dtype=torch.long).to(device)\n",
    "        \n",
    "        out = model(words)\n",
    "        loss = loss_fn(out, labels)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    if epoch % 90 == 20:\n",
    "        print(f\"epoch:{epoch}/{num_epochs} |train loss: {train_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d88cf743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('l1.weight',\n",
       "              tensor([[ 3.7893e-01,  6.5365e-01, -4.3237e-01, -1.2081e-01, -3.5467e-01,\n",
       "                        5.6419e-01, -1.4458e-01, -2.6234e-01, -2.8673e-01, -1.7753e-01,\n",
       "                       -1.3388e-01, -1.2837e-01, -1.4844e-02, -1.1348e-01,  4.8775e-01,\n",
       "                        6.0846e-01, -1.0560e-01,  4.7406e-01, -2.5013e-01,  5.0609e-01,\n",
       "                       -1.5497e-01, -3.5589e-01,  4.9539e-01, -3.8061e-01, -3.2500e-01,\n",
       "                       -2.1935e-01, -2.1275e-01,  1.3295e-04, -8.8978e-02,  6.6409e-01,\n",
       "                       -1.0139e-01,  5.1903e-01,  2.3773e-01,  3.8048e-01,  1.2525e-01,\n",
       "                        2.5789e-01, -3.1619e-01,  7.2091e-01, -1.8488e-01,  4.6369e-02,\n",
       "                       -1.2213e-01,  3.6950e-01, -1.3079e-01,  4.7420e-03,  3.2010e-01,\n",
       "                       -2.5153e-01, -1.0607e-01,  7.7273e-01, -3.0879e-01,  6.6077e-01,\n",
       "                        7.2442e-01,  4.7315e-01, -7.2429e-02, -2.4301e-01,  3.4782e-02,\n",
       "                       -1.4506e-01, -1.0749e-01,  1.7695e-01],\n",
       "                      [-2.4545e-01,  4.8109e-01,  4.1540e-01, -2.6119e-01,  3.4600e-02,\n",
       "                        7.5620e-03,  2.2740e-01,  1.1827e-01,  5.8926e-01,  1.6324e-01,\n",
       "                       -2.1765e-01,  7.7430e-01,  7.3371e-01,  6.3078e-01,  4.4094e-01,\n",
       "                        3.5758e-01,  4.8098e-01,  3.0109e-01, -1.6548e-01, -7.6302e-02,\n",
       "                        4.4980e-01, -3.1707e-01, -1.1152e-01, -3.2935e-01, -3.9693e-01,\n",
       "                        3.5236e-01,  6.1257e-01, -3.4340e-01,  5.6372e-01,  6.9959e-01,\n",
       "                        5.5430e-01,  3.2823e-01, -9.6806e-02,  3.7088e-01,  6.3530e-01,\n",
       "                       -2.1571e-01,  3.6523e-01,  6.6754e-01,  3.8064e-01,  4.2048e-01,\n",
       "                        6.2290e-01,  4.6311e-01,  3.8786e-01,  3.8970e-01,  7.1661e-02,\n",
       "                        5.4260e-01,  7.1310e-01,  5.2426e-01,  8.3111e-01,  5.8251e-01,\n",
       "                       -5.2740e-01, -1.5057e-01,  2.0976e-01,  5.7569e-01,  5.7623e-01,\n",
       "                        3.1286e-01,  1.7984e-01,  2.1971e-02],\n",
       "                      [-2.3652e-03,  3.2016e-01,  4.6592e-01,  1.4615e-01,  3.1674e-01,\n",
       "                        2.1918e-01,  2.9553e-01,  3.1593e-01,  3.0402e-01,  2.6681e-01,\n",
       "                        1.1167e-01,  5.9669e-02,  1.8476e-01,  3.9575e-02,  4.3152e-01,\n",
       "                        3.1221e-01,  9.8243e-02,  4.0854e-01,  1.7031e-01,  2.1045e-01,\n",
       "                       -3.9610e-01,  2.8596e-01,  2.7064e-01,  2.2824e-01,  2.4816e-01,\n",
       "                       -2.7576e-01,  2.6629e-01,  2.1701e-01, -1.0977e-01,  2.5747e-01,\n",
       "                       -8.4941e-02,  3.2537e-01,  2.1745e-01,  2.8596e-01,  8.6333e-02,\n",
       "                       -2.6567e-02,  3.8936e-01,  3.9436e-01, -1.4644e-01,  7.4605e-02,\n",
       "                        3.4685e-01,  4.1420e-01,  4.2734e-01,  2.4121e-01,  2.5569e-01,\n",
       "                       -3.7617e-01,  7.9047e-02,  2.9802e-01,  3.3986e-01,  4.6469e-01,\n",
       "                        3.0142e-01,  2.4763e-01,  1.1469e-01, -4.1510e-01,  4.2117e-02,\n",
       "                       -2.4321e-01,  2.2181e-01,  3.1373e-01],\n",
       "                      [ 2.8366e-01,  5.4221e-01, -3.3348e-01, -2.6324e-01, -5.3987e-01,\n",
       "                        7.9438e-01, -2.1031e-01, -3.3725e-01, -9.6601e-02, -2.4258e-01,\n",
       "                       -2.5141e-01,  5.8276e-01, -1.5617e-01,  5.9662e-01,  2.0695e-01,\n",
       "                        2.2610e-01,  2.6009e-01,  1.8175e-01, -3.5187e-01,  7.1786e-01,\n",
       "                       -3.5039e-01, -5.7322e-01,  3.4464e-01, -6.0036e-01, -6.0329e-01,\n",
       "                       -1.6182e-01,  1.2294e-01, -1.2439e-01, -1.2000e-01,  4.6899e-01,\n",
       "                        2.8886e-02,  4.1051e-01,  5.0107e-01,  2.9102e-01,  6.3041e-01,\n",
       "                        2.5912e-01, -3.4198e-01,  1.0117e-01,  2.6365e-01,  5.3695e-02,\n",
       "                       -1.9522e-01,  2.0204e-01, -1.0120e-01, -2.8032e-01,  5.4848e-01,\n",
       "                       -2.8666e-01,  4.7455e-01,  1.2431e-01, -9.5327e-02,  1.1213e-01,\n",
       "                        7.7367e-01,  5.0495e-01, -2.1572e-01, -3.8899e-01,  3.4563e-01,\n",
       "                       -2.0411e-01, -1.3450e-01,  2.2817e-01],\n",
       "                      [-2.9960e-01, -1.4473e-01, -4.9288e-01,  2.8616e-01,  3.2770e-01,\n",
       "                        7.8662e-01, -1.5543e-01, -1.9475e-01, -5.8836e-01, -4.1213e-01,\n",
       "                        5.7009e-01, -2.1520e-01,  3.4516e-01, -1.7146e-01,  3.2367e-02,\n",
       "                       -1.4415e-01,  2.6117e-02, -1.1367e-01,  3.9263e-01,  6.3475e-01,\n",
       "                        3.4177e-01,  5.4746e-01, -3.2130e-01,  5.3966e-01,  6.8300e-01,\n",
       "                        2.9395e-01, -1.7561e-01,  3.5259e-01,  5.0564e-01, -2.8618e-03,\n",
       "                        4.1886e-01, -2.9126e-01,  4.5508e-01,  5.4603e-02, -2.5365e-01,\n",
       "                        1.2600e-01, -4.6440e-01, -1.1324e-02, -1.6676e-01,  3.1555e-01,\n",
       "                       -5.4434e-01,  1.4359e-02, -2.1208e-01, -2.4049e-03,  5.9515e-01,\n",
       "                        3.6721e-01, -2.1247e-01, -1.8129e-01, -4.6621e-01,  1.4653e-01,\n",
       "                       -8.1207e-01, -1.9100e-01,  4.2403e-01,  4.4454e-01, -2.2456e-01,\n",
       "                        2.0095e-01, -1.2177e-01,  1.0109e-01],\n",
       "                      [ 5.4355e-02,  6.1939e-01, -1.4525e-01, -2.3576e-01, -8.8411e-02,\n",
       "                       -2.3731e-01, -7.4469e-02, -2.3683e-01, -1.0072e-01, -2.4981e-01,\n",
       "                       -9.9535e-02, -4.1040e-02,  3.8138e-01, -1.1611e-01,  4.4422e-01,\n",
       "                        4.9163e-01, -6.4170e-02,  3.6357e-01, -1.6746e-02, -2.3738e-01,\n",
       "                        4.1112e-01, -1.9645e-01,  1.4701e-01, -1.8962e-01, -2.0134e-01,\n",
       "                       -3.6683e-01, -1.7577e-01, -1.0901e-01,  3.8031e-01,  5.4479e-01,\n",
       "                        3.8826e-01,  5.2817e-01, -3.0246e-01,  5.1865e-01, -2.3527e-02,\n",
       "                       -1.0638e-01, -9.5239e-02,  5.0229e-01, -8.2562e-02,  3.3555e-01,\n",
       "                        8.3780e-02,  5.1752e-01, -6.0273e-02,  3.2947e-02, -1.5280e-01,\n",
       "                        4.7645e-01,  4.9493e-02,  4.2161e-01, -2.9981e-01,  5.2042e-01,\n",
       "                        2.5799e-01,  1.2485e-01,  2.2879e-01,  6.1909e-01,  6.2044e-02,\n",
       "                        4.6149e-01,  4.0123e-02,  2.1796e-01],\n",
       "                      [-1.6787e-02, -3.9232e-01, -3.1144e-01,  2.6890e-01,  3.2140e-01,\n",
       "                       -4.8232e-01, -2.3557e-02, -2.6699e-01, -4.4747e-01, -1.9748e-01,\n",
       "                        3.1952e-01, -1.6513e-01,  1.4582e-01, -2.7543e-01, -6.7517e-02,\n",
       "                       -1.6078e-01, -2.0881e-01, -1.2803e-01,  2.9140e-01, -4.7787e-01,\n",
       "                        2.1027e-01,  6.3737e-01, -1.5929e-01,  6.4142e-01,  5.3928e-01,\n",
       "                        4.6407e-01, -4.5427e-02,  4.1603e-01,  3.8642e-01, -1.4189e-01,\n",
       "                        2.4940e-02, -2.9619e-01, -2.3105e-01, -5.2814e-02, -1.9728e-01,\n",
       "                        7.4292e-02, -4.6766e-01, -5.5558e-02, -2.0689e-01,  2.1622e-01,\n",
       "                       -5.3448e-01, -6.0776e-02, -1.8947e-01, -1.1304e-01, -3.0701e-01,\n",
       "                        3.0916e-01, -1.6516e-01, -1.9937e-01, -3.4637e-01, -9.7810e-02,\n",
       "                       -2.9576e-01, -1.5312e-01,  4.2651e-01,  2.5160e-01, -3.9887e-02,\n",
       "                        1.8407e-01, -1.4878e-01,  1.9576e-01],\n",
       "                      [ 6.5105e-01,  2.9066e-01,  6.4864e-01,  2.7594e-01,  6.0444e-01,\n",
       "                       -5.0046e-01,  3.1193e-01,  5.8368e-01,  4.4200e-01,  4.5340e-01,\n",
       "                        3.2595e-01, -1.7642e-01,  9.6439e-02, -4.0370e-01,  1.2693e-02,\n",
       "                        2.7596e-02, -2.0606e-01,  1.1880e-01,  4.2787e-01, -5.9925e-01,\n",
       "                       -3.4267e-01,  5.3571e-01,  4.5987e-01,  4.5734e-01,  5.8790e-01,\n",
       "                        5.4233e-03,  2.0634e-01,  2.1850e-01, -4.8024e-01,  9.3961e-02,\n",
       "                       -2.5295e-01, -1.1009e-01, -5.1601e-01,  2.1125e-02, -2.3112e-01,\n",
       "                        4.7618e-01,  4.8670e-01,  1.9771e-01, -3.0886e-01, -1.0518e-01,\n",
       "                        5.9508e-01,  8.0202e-02,  2.9204e-01,  5.1476e-01, -3.9303e-01,\n",
       "                       -4.2700e-01, -1.7639e-01,  7.3544e-02,  2.0657e-01,  6.5722e-02,\n",
       "                        9.3669e-01,  4.6830e-01,  2.2674e-01, -5.9221e-01, -2.1072e-01,\n",
       "                       -3.0437e-01,  4.7275e-01,  4.3222e-01]], device='cuda:0')),\n",
       "             ('l1.bias',\n",
       "              tensor([0.5864, 0.5074, 0.7278, 0.6033, 0.8120, 0.2373, 0.5201, 0.5992],\n",
       "                     device='cuda:0')),\n",
       "             ('l2.weight',\n",
       "              tensor([[-0.1599,  0.8859,  0.7806, -0.0299, -0.7749,  0.4243, -0.8530,  0.4471],\n",
       "                      [ 1.2840, -0.8846,  1.1695,  0.7212,  0.5015, -0.3392,  0.1329,  0.8904],\n",
       "                      [ 0.0047, -0.3634,  0.2233, -0.2996,  0.1130, -0.3646, -0.3466,  0.1338],\n",
       "                      [ 0.6605, -0.2538,  0.5129,  0.1016, -0.9878,  1.1882, -0.3004,  1.2076],\n",
       "                      [-0.8743,  0.2884,  0.5282, -0.9286,  1.1879,  0.0282,  1.2949,  0.5160],\n",
       "                      [-0.4663,  1.1902,  0.8047, -0.4602, -0.1014,  0.0207, -1.1498,  0.3793],\n",
       "                      [ 0.4101,  0.4012,  0.0145, -0.5582,  0.5093,  0.8445,  1.0423, -0.1258],\n",
       "                      [ 1.0319,  1.1789,  0.4383,  0.9650,  0.7417,  0.9024, -0.7632, -1.2044]],\n",
       "                     device='cuda:0')),\n",
       "             ('l2.bias',\n",
       "              tensor([ 0.2570,  0.6032, -0.3217,  0.2142,  0.7841,  0.0816, -0.2428,  0.2692],\n",
       "                     device='cuda:0')),\n",
       "             ('l3.weight',\n",
       "              tensor([[ 0.5598, -0.9760,  0.0586, -1.2355, -0.7337,  0.5436, -0.3487,  0.6838],\n",
       "                      [ 0.1193, -0.1836, -0.2335,  0.3382, -1.0895,  0.0276,  0.5187,  0.2411],\n",
       "                      [-0.8679,  0.8055,  0.2861, -1.3018, -0.3234, -0.7715, -0.8982,  0.7780],\n",
       "                      [-0.7075,  0.6343, -0.2456, -0.5066,  0.8747, -0.7737,  0.3047, -1.2085],\n",
       "                      [-0.4004, -1.1768,  0.3105, -0.8279,  0.4722, -0.3773,  0.6814,  0.3507],\n",
       "                      [ 0.4052, -0.2467,  0.3155,  0.3218,  0.1210,  0.8204, -0.4671, -0.7031],\n",
       "                      [ 0.1397,  0.7786, -0.2837,  0.8732, -0.7383, -1.3675, -0.9746, -0.6478]],\n",
       "                     device='cuda:0')),\n",
       "             ('l3.bias',\n",
       "              tensor([-0.1981, -0.6494,  0.1241,  0.5073, -0.2409, -0.2191,  0.0118],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "554739ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"model_state\":model.state_dict(),\n",
    "    \"input_size\":input_size,\n",
    "    \"hidden_size\":hidden_size,\n",
    "    \"num_classes\":num_classes,\n",
    "    \"all_words\":all_words,\n",
    "    \"tags\":tags\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fbfd880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(data, \"data.pth\")\n",
    "print(f'training complete file saved to {\"data.pth\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "94fcf907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode():\n",
    "#     for (words, labels) in train_loader:\n",
    "#         words = words.to(device)\n",
    "#         lables = labels.to(device)\n",
    "        \n",
    "#         out = model(words)\n",
    "#         loss = loss_fn(out, labels)\n",
    "#         pred_probs = torch.softmax(out, dim=1)\n",
    "#         preds = torch.argmax(pred_probs, dim=1)\n",
    "        \n",
    "#         print(tags[preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fffa36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try this\n",
    "# from torch.utils.data import TensorDataset\n",
    "\n",
    "# dataset = TensorDataset(x_train, y_train)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "58cd46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# count = Counter(all_words)\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c0613d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "99ef7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
